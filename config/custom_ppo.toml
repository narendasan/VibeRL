[experiment]
name = "custom_ppo_experiment1"
root_seed = 42
num_agent_seeds = 16
ckpt_dir = "ckpts"
tags = ["test"]
algorithm = "ppo"
max_ckpt_to_keep = 5
results_dir = "results"
log_dir = "logs"
log_level = "INFO"

[algorithm]
actor_lr = 3e-4
critic_lr = 3e-4
actor_hidden_dims = [128, 128]
critic_hidden_dims = [128, 128]
actor_activation_fn = "nnx.Tanh"
critic_activation_fn = "nnx.Tanh"
gamma = 0.99
gae_lambda = 0.95
num_minibatches = 8
num_update_epochs = 4
normalize_advantages = false      #true
surrogate_clip_coef = 0.2
clip_v_loss = true
v_clip_coef = 0.2
entropy_coef = 0.0
v_coef = 2
max_grad_norm = 1
target_kl = 0.0
normalize_obs = false             #true
normalize_returns = false         #true
v_bootstrap = false
weight_decay = 0.0
clip_obs_rew = true
rollout_len = 128


[algorithm.env_params]
backend = "positional"

[algorithm.agent_kwargs]
activation = "relu"
